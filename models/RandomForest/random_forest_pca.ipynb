{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Implementation on scaled reduced dataset with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\movil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Utilities\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Models\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed for reproductibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read clean (scaled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = pd.read_csv('../../Data/dataset_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_PCA = ['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10',\n",
    "           'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16', 'PC17', 'PC18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>PC12</th>\n",
       "      <th>PC13</th>\n",
       "      <th>PC14</th>\n",
       "      <th>PC15</th>\n",
       "      <th>PC16</th>\n",
       "      <th>PC17</th>\n",
       "      <th>PC18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.230656</td>\n",
       "      <td>-0.540199</td>\n",
       "      <td>0.275241</td>\n",
       "      <td>0.348734</td>\n",
       "      <td>0.442168</td>\n",
       "      <td>-0.244893</td>\n",
       "      <td>-0.305579</td>\n",
       "      <td>-0.388014</td>\n",
       "      <td>0.483440</td>\n",
       "      <td>-0.050057</td>\n",
       "      <td>0.114171</td>\n",
       "      <td>0.037729</td>\n",
       "      <td>-0.133432</td>\n",
       "      <td>0.084029</td>\n",
       "      <td>0.211571</td>\n",
       "      <td>-0.000299</td>\n",
       "      <td>0.276030</td>\n",
       "      <td>0.133585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.578532</td>\n",
       "      <td>-0.273813</td>\n",
       "      <td>-0.207024</td>\n",
       "      <td>0.202237</td>\n",
       "      <td>0.438744</td>\n",
       "      <td>-0.422858</td>\n",
       "      <td>0.108360</td>\n",
       "      <td>-0.469457</td>\n",
       "      <td>0.476055</td>\n",
       "      <td>0.098184</td>\n",
       "      <td>0.022312</td>\n",
       "      <td>0.125669</td>\n",
       "      <td>0.187688</td>\n",
       "      <td>-0.019637</td>\n",
       "      <td>-0.181937</td>\n",
       "      <td>-0.064250</td>\n",
       "      <td>-0.107400</td>\n",
       "      <td>0.057437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.207271</td>\n",
       "      <td>1.096294</td>\n",
       "      <td>-0.124524</td>\n",
       "      <td>-0.014919</td>\n",
       "      <td>0.302102</td>\n",
       "      <td>0.276747</td>\n",
       "      <td>0.024807</td>\n",
       "      <td>-0.079499</td>\n",
       "      <td>0.016929</td>\n",
       "      <td>0.018033</td>\n",
       "      <td>-0.071089</td>\n",
       "      <td>-0.003510</td>\n",
       "      <td>-0.020689</td>\n",
       "      <td>-0.065503</td>\n",
       "      <td>-0.117356</td>\n",
       "      <td>-0.056667</td>\n",
       "      <td>-0.133169</td>\n",
       "      <td>-0.121348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.549501</td>\n",
       "      <td>-0.271749</td>\n",
       "      <td>0.166219</td>\n",
       "      <td>0.161220</td>\n",
       "      <td>0.278617</td>\n",
       "      <td>-0.671476</td>\n",
       "      <td>-0.287128</td>\n",
       "      <td>0.591844</td>\n",
       "      <td>-0.668737</td>\n",
       "      <td>-0.173965</td>\n",
       "      <td>-0.421168</td>\n",
       "      <td>-0.101647</td>\n",
       "      <td>-0.332900</td>\n",
       "      <td>-0.157359</td>\n",
       "      <td>0.086729</td>\n",
       "      <td>0.130933</td>\n",
       "      <td>-0.221770</td>\n",
       "      <td>-0.134654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.605220</td>\n",
       "      <td>-0.210550</td>\n",
       "      <td>-0.406984</td>\n",
       "      <td>0.455269</td>\n",
       "      <td>-0.336895</td>\n",
       "      <td>0.182399</td>\n",
       "      <td>0.298030</td>\n",
       "      <td>0.309622</td>\n",
       "      <td>0.071143</td>\n",
       "      <td>-0.035126</td>\n",
       "      <td>0.191219</td>\n",
       "      <td>-0.142084</td>\n",
       "      <td>0.191455</td>\n",
       "      <td>0.036069</td>\n",
       "      <td>-0.138503</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>-0.030649</td>\n",
       "      <td>0.106555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0  0.230656 -0.540199  0.275241  0.348734  0.442168 -0.244893 -0.305579   \n",
       "1 -0.578532 -0.273813 -0.207024  0.202237  0.438744 -0.422858  0.108360   \n",
       "2 -0.207271  1.096294 -0.124524 -0.014919  0.302102  0.276747  0.024807   \n",
       "3 -0.549501 -0.271749  0.166219  0.161220  0.278617 -0.671476 -0.287128   \n",
       "4 -0.605220 -0.210550 -0.406984  0.455269 -0.336895  0.182399  0.298030   \n",
       "\n",
       "        PC8       PC9      PC10      PC11      PC12      PC13      PC14  \\\n",
       "0 -0.388014  0.483440 -0.050057  0.114171  0.037729 -0.133432  0.084029   \n",
       "1 -0.469457  0.476055  0.098184  0.022312  0.125669  0.187688 -0.019637   \n",
       "2 -0.079499  0.016929  0.018033 -0.071089 -0.003510 -0.020689 -0.065503   \n",
       "3  0.591844 -0.668737 -0.173965 -0.421168 -0.101647 -0.332900 -0.157359   \n",
       "4  0.309622  0.071143 -0.035126  0.191219 -0.142084  0.191455  0.036069   \n",
       "\n",
       "       PC15      PC16      PC17      PC18  \n",
       "0  0.211571 -0.000299  0.276030  0.133585  \n",
       "1 -0.181937 -0.064250 -0.107400  0.057437  \n",
       "2 -0.117356 -0.056667 -0.133169 -0.121348  \n",
       "3  0.086729  0.130933 -0.221770 -0.134654  \n",
       "4 -0.138503  0.001297 -0.030649  0.106555  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train= pd.read_csv('../../DimensionalityReductionData/X_train_PCA.csv', names=columns_PCA)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>PC12</th>\n",
       "      <th>PC13</th>\n",
       "      <th>PC14</th>\n",
       "      <th>PC15</th>\n",
       "      <th>PC16</th>\n",
       "      <th>PC17</th>\n",
       "      <th>PC18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.325189</td>\n",
       "      <td>-0.474065</td>\n",
       "      <td>0.148350</td>\n",
       "      <td>0.015025</td>\n",
       "      <td>0.453967</td>\n",
       "      <td>-0.382437</td>\n",
       "      <td>0.009063</td>\n",
       "      <td>0.696200</td>\n",
       "      <td>-0.577426</td>\n",
       "      <td>-0.029937</td>\n",
       "      <td>-0.099144</td>\n",
       "      <td>0.654157</td>\n",
       "      <td>0.475839</td>\n",
       "      <td>0.289828</td>\n",
       "      <td>-0.034359</td>\n",
       "      <td>-0.584359</td>\n",
       "      <td>0.783886</td>\n",
       "      <td>-0.206918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.553038</td>\n",
       "      <td>-0.060147</td>\n",
       "      <td>0.246432</td>\n",
       "      <td>-0.094217</td>\n",
       "      <td>-0.152499</td>\n",
       "      <td>-0.133879</td>\n",
       "      <td>0.046601</td>\n",
       "      <td>-0.127948</td>\n",
       "      <td>-0.063073</td>\n",
       "      <td>-0.262155</td>\n",
       "      <td>0.036293</td>\n",
       "      <td>-0.084048</td>\n",
       "      <td>-0.114584</td>\n",
       "      <td>0.030450</td>\n",
       "      <td>0.102251</td>\n",
       "      <td>-0.048580</td>\n",
       "      <td>0.100263</td>\n",
       "      <td>0.069443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.543513</td>\n",
       "      <td>-0.099255</td>\n",
       "      <td>0.273981</td>\n",
       "      <td>-0.140697</td>\n",
       "      <td>-0.202855</td>\n",
       "      <td>-0.145719</td>\n",
       "      <td>-0.165479</td>\n",
       "      <td>-0.040533</td>\n",
       "      <td>-0.045461</td>\n",
       "      <td>-0.230001</td>\n",
       "      <td>0.047889</td>\n",
       "      <td>-0.076919</td>\n",
       "      <td>-0.013481</td>\n",
       "      <td>0.034937</td>\n",
       "      <td>0.047416</td>\n",
       "      <td>-0.038551</td>\n",
       "      <td>0.040234</td>\n",
       "      <td>0.096922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.604992</td>\n",
       "      <td>0.850389</td>\n",
       "      <td>0.205670</td>\n",
       "      <td>0.134501</td>\n",
       "      <td>0.422158</td>\n",
       "      <td>0.448003</td>\n",
       "      <td>-0.124164</td>\n",
       "      <td>-0.002779</td>\n",
       "      <td>0.023872</td>\n",
       "      <td>-0.005055</td>\n",
       "      <td>-0.010426</td>\n",
       "      <td>-0.033946</td>\n",
       "      <td>-0.181834</td>\n",
       "      <td>0.042114</td>\n",
       "      <td>0.137483</td>\n",
       "      <td>0.011521</td>\n",
       "      <td>0.138021</td>\n",
       "      <td>0.009279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.222045</td>\n",
       "      <td>1.101761</td>\n",
       "      <td>-0.093482</td>\n",
       "      <td>-0.005867</td>\n",
       "      <td>0.283825</td>\n",
       "      <td>0.294311</td>\n",
       "      <td>0.032426</td>\n",
       "      <td>-0.116046</td>\n",
       "      <td>0.009989</td>\n",
       "      <td>-0.017200</td>\n",
       "      <td>-0.072850</td>\n",
       "      <td>-0.009081</td>\n",
       "      <td>-0.097862</td>\n",
       "      <td>-0.067777</td>\n",
       "      <td>-0.070239</td>\n",
       "      <td>-0.058562</td>\n",
       "      <td>-0.076902</td>\n",
       "      <td>-0.149065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0  0.325189 -0.474065  0.148350  0.015025  0.453967 -0.382437  0.009063   \n",
       "1 -0.553038 -0.060147  0.246432 -0.094217 -0.152499 -0.133879  0.046601   \n",
       "2 -0.543513 -0.099255  0.273981 -0.140697 -0.202855 -0.145719 -0.165479   \n",
       "3  0.604992  0.850389  0.205670  0.134501  0.422158  0.448003 -0.124164   \n",
       "4 -0.222045  1.101761 -0.093482 -0.005867  0.283825  0.294311  0.032426   \n",
       "\n",
       "        PC8       PC9      PC10      PC11      PC12      PC13      PC14  \\\n",
       "0  0.696200 -0.577426 -0.029937 -0.099144  0.654157  0.475839  0.289828   \n",
       "1 -0.127948 -0.063073 -0.262155  0.036293 -0.084048 -0.114584  0.030450   \n",
       "2 -0.040533 -0.045461 -0.230001  0.047889 -0.076919 -0.013481  0.034937   \n",
       "3 -0.002779  0.023872 -0.005055 -0.010426 -0.033946 -0.181834  0.042114   \n",
       "4 -0.116046  0.009989 -0.017200 -0.072850 -0.009081 -0.097862 -0.067777   \n",
       "\n",
       "       PC15      PC16      PC17      PC18  \n",
       "0 -0.034359 -0.584359  0.783886 -0.206918  \n",
       "1  0.102251 -0.048580  0.100263  0.069443  \n",
       "2  0.047416 -0.038551  0.040234  0.096922  \n",
       "3  0.137483  0.011521  0.138021  0.009279  \n",
       "4 -0.070239 -0.058562 -0.076902 -0.149065  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv('../../DimensionalityReductionData/X_test_PCA.csv', names=columns_PCA)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do Train-Test Split to define y_train, y_test (both are raings)\n",
    "!!!! IMPORTANT use random_state as defined in Dimension Reduction DATA SPLIT!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = train_test_split(df_scaled['averageRating'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now everything is defined (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save and print metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(model_name, y_true, y_pred):\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Weighted F1': f1_score(y_true, y_pred, average='weighted'),\n",
    "        'Weighted Precision': precision_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "        'Weighted Recall': recall_score(y_true, y_pred, average='weighted'),\n",
    "        'Macro-Averaged Precision': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'Macro-Averaged Recall': recall_score(y_true, y_pred, average='macro'),\n",
    "        'F1': str(f1_score(y_true, y_pred, average=None)),\n",
    "        'Precision': str( precision_score(y_true, y_pred, average=None, zero_division=0)),\n",
    "    }\n",
    "    \n",
    "    # Print the metrics\n",
    "    print(f\"Metrics for {model_name}:\")\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        try:\n",
    "            print(f\"{metric_name}: {metric_value:.4f}\")\n",
    "        except:\n",
    "            print(f\"{metric_name}: {metric_value}\")\n",
    "    \n",
    "    # Print the classification report\n",
    "    print(\"classification report\")\n",
    "    report = classification_report(y_true, y_pred, target_names=['Class 0', 'Class 1'], zero_division=0)\n",
    "    print(report)\n",
    "\n",
    "    print(\"Confusion Matrix\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cmd = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    cmd.plot()\n",
    "    \n",
    "    plt.title(f'Confusion matrix for model {model_name} (Accuracy:{metrics[\"Accuracy\"]:.4f})')\n",
    "    plt.show()\n",
    "    \n",
    "    # Create df to store metrics\n",
    "    df_metrics = pd.DataFrame(metrics, index=[model_name])\n",
    "    \n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7331778814123917\n",
      "F1 score: [0.73866232 0.72745832]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=seed)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"F1 score:\", f1_score(y_test, predictions, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search CV - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "The parameters with the highest score:  {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'bootstrap': [True, False]  # Method of selecting samples for training each tree\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier(random_state=seed)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"The parameters with the highest score: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                params  mean_test_score\n",
      "42   {'bootstrap': True, 'max_depth': 10, 'min_samp...         0.727614\n",
      "55   {'bootstrap': True, 'max_depth': 10, 'min_samp...         0.727364\n",
      "207  {'bootstrap': False, 'max_depth': 10, 'min_sam...         0.727280\n",
      "211  {'bootstrap': False, 'max_depth': 10, 'min_sam...         0.727280\n",
      "70   {'bootstrap': True, 'max_depth': 10, 'min_samp...         0.727031\n",
      "59   {'bootstrap': True, 'max_depth': 10, 'min_samp...         0.726864\n",
      "51   {'bootstrap': True, 'max_depth': 10, 'min_samp...         0.726864\n",
      "71   {'bootstrap': True, 'max_depth': 10, 'min_samp...         0.726780\n",
      "190  {'bootstrap': False, 'max_depth': 10, 'min_sam...         0.726780\n",
      "43   {'bootstrap': True, 'max_depth': 10, 'min_samp...         0.726697\n"
     ]
    }
   ],
   "source": [
    "cv_results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Show top 10 parameters for this model\n",
    "minimalistic_results = cv_results_df[['params', 'mean_test_score']]\n",
    "sorted_results = minimalistic_results.sort_values(by='mean_test_score', ascending=False)\n",
    "\n",
    "print(sorted_results.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for RF-PCA-GS-CV1:\n",
      "Accuracy: 0.7342\n",
      "Weighted F1: 0.7339\n",
      "Weighted Precision: 0.7343\n",
      "Weighted Recall: 0.7342\n",
      "Macro-Averaged Precision: 0.7344\n",
      "Macro-Averaged Recall: 0.7335\n",
      "F1: [0.74602164 0.721174  ]\n",
      "Precision: [0.73112913 0.73766976]\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.73      0.76      0.75      1539\n",
      "     Class 1       0.74      0.71      0.72      1463\n",
      "\n",
      "    accuracy                           0.73      3002\n",
      "   macro avg       0.73      0.73      0.73      3002\n",
      "weighted avg       0.73      0.73      0.73      3002\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(X_test)\n",
    "_ = calculate_metrics('RF-PCA-GS-CV1', y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters from place:  0   {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Accuracy for chosen parameters: 0.7341772151898734\n",
      "Parameters from place:  1   {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Accuracy for chosen parameters: 0.7348434377081945\n",
      "Parameters from place:  2   {'bootstrap': False, 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Accuracy for chosen parameters: 0.740506329113924\n",
      "Parameters from place:  3   {'bootstrap': False, 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Accuracy for chosen parameters: 0.740506329113924\n",
      "Parameters from place:  4   {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Accuracy for chosen parameters: 0.7391738840772818\n",
      "Parameters from place:  5   {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Accuracy for chosen parameters: 0.7381745502998002\n",
      "Parameters from place:  6   {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Accuracy for chosen parameters: 0.737508327781479\n",
      "Parameters from place:  7   {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Accuracy for chosen parameters: 0.7358427714856762\n",
      "Parameters from place:  8   {'bootstrap': False, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Accuracy for chosen parameters: 0.7365089940039974\n",
      "Parameters from place:  9   {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Accuracy for chosen parameters: 0.737508327781479\n"
     ]
    }
   ],
   "source": [
    "# Predicting using other alternatives of fine-tuning from top 10 performances\n",
    "other_alternatives = []\n",
    "# Choose a set of parameters from sorted_results\n",
    "for i in range(10):\n",
    "\n",
    "  params = sorted_results.iloc[i]['params']\n",
    "  print(\"Parameters from place: \", i, \" \", params)\n",
    "\n",
    "  model = RandomForestClassifier(random_state=seed, **params)\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  predictions = model.predict(X_test)\n",
    "\n",
    "  chosen_accuracy = accuracy_score(y_test, predictions)\n",
    "  print(\"Accuracy for chosen parameters:\", chosen_accuracy)\n",
    "  other_alternatives.append((chosen_accuracy,params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best from top 10\n",
    "best_tuple = max(other_alternatives, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy and parameters after running the algorithm using other alternatives of fine tuning from top 10 performances\n",
      "0.740506329113924\n",
      "{'bootstrap': False, 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best accuracy and parameters after running the algorithm using other alternatives of fine tuning from top 10 performances\")\n",
    "print(best_tuple[0])\n",
    "print(best_tuple[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters from place:  0   {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Accuracy for chosen parameters: 0.8089962515618492\n",
      "Parameters from place:  1   {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameters from place: \u001b[39m\u001b[38;5;124m\"\u001b[39m, i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, params)\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[0;32m     14\u001b[0m chosen_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_train, predictions)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run on training sample\n",
    "\n",
    "# Choose a set of parameters from sorted_results\n",
    "for i in range(10):\n",
    "\n",
    "  params = sorted_results.iloc[i]['params']\n",
    "  print(\"Parameters from place: \", i, \" \", params)\n",
    "\n",
    "  model = RandomForestClassifier(random_state=42, **params)\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  predictions = model.predict(X_train)\n",
    "\n",
    "  chosen_accuracy = accuracy_score(y_train, predictions)\n",
    "  print(\"Accuracy for chosen parameters:\", chosen_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies=[]\n",
    "max_depths=[]\n",
    "for i in reversed(range(1,15)):\n",
    "  model = RandomForestClassifier(random_state=seed, max_depth=i)\n",
    "  model.fit(X_train, y_train)\n",
    "  predictions = model.predict(X_train)\n",
    "  accuracy = accuracy_score(y_train, predictions)\n",
    "  max_depths.append(i)\n",
    "  accuracies.append(accuracy)\n",
    "  print(\"Accuracy for max depth :\", i, \" \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_depths, accuracies, marker='o', linestyle='-', color='b')\n",
    "\n",
    "plt.title('Accuracy related to the maximum depth of the model')\n",
    "plt.xlabel('Maximum depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report of best model from alternatives of fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=seed, **best_tuple[1])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "current_accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "report = classification_report(y_test, predictions, output_dict=True, zero_division=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics('RF-PCA-alternatives', y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
