{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tsv_qz(file_path, zip=True, sep='\\t'):\n",
    "    if zip:\n",
    "        with gzip.open(file_path, 'rt') as f:\n",
    "            return pd.read_csv(f, delimiter=sep)\n",
    "    else:\n",
    "        return pd.read_csv(file_path, delimiter=',')\n",
    "\n",
    "def write_tsv_qz(df, file_path, zip=True):\n",
    "    if zip:\n",
    "        with gzip.open(file_path, 'wt') as f:\n",
    "            df.to_csv(f, sep='\\t', index=False)\n",
    "    else:\n",
    "        df.to_csv(file_path, sep=',', index=False)\n",
    "    \n",
    "def convert_string_to_year(input_string):\n",
    "    if len(input_string) == 4:\n",
    "        return int(input_string)\n",
    "    elif '/' in input_string:\n",
    "        if 'â€”' in input_string:\n",
    "            return None\n",
    "        \n",
    "        aux = input_string.split('/')[2]\n",
    "        if len(aux) == 4:\n",
    "            return int(aux)\n",
    "        else:\n",
    "            return int('19' + aux)\n",
    "    else:\n",
    "        for word in input_string.split():\n",
    "            if len(word) == 4 and word.isdigit():\n",
    "                return int(word)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_akas_tsv = 'RawData/title.akas.tsv.gz'\n",
    "title_basics_tsv = 'RawData/title.basics.tsv.gz'\n",
    "title_ratings_tsv = 'RawData/title.ratings.tsv.gz'\n",
    "title_principals_tsv = 'RawData/title.principals.tsv.gz'\n",
    "title_crew_tsv = 'RawData/title.crew.tsv.gz'\n",
    "books_csv = 'RawData/books_1.Best_Books_Ever.csv'\n",
    "boxoffice_csv = 'RawData/boxoffice.csv'\n",
    "data_api_csv = 'RawData/data_api.csv'\n",
    "wikidata_csv = 'RawData/wikidata_query.csv'\n",
    "\n",
    "join_column_title_akas = 'titleId'\n",
    "join_column_title_basics = 'tconst'\n",
    "join_column_title_ratings = 'tconst'\n",
    "join_column_title_principals = 'tconst'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining the movies and boxoffice datasets (plus wikidata and api data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the main tsv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/td/hh6f_yhd28q6g56x8wwsht340000gn/T/ipykernel_11611/1708109223.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(f, delimiter=sep)\n"
     ]
    }
   ],
   "source": [
    "df_title_basics = read_tsv_qz(title_basics_tsv)\n",
    "df_title_basics = df_title_basics[df_title_basics['titleType'] == 'movie']\n",
    "df_title_basics = df_title_basics.drop('endYear', axis=1)\n",
    "df_title_basics = df_title_basics.drop('titleType', axis=1)\n",
    "df_title_basics = df_title_basics[df_title_basics['startYear'] < '2024']\n",
    "# remove rows that are not a movie,\n",
    "# remove the endYear column as it is not relevant for movies (it is used for TV series)\n",
    "# remove movies that are not released yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the boxoffice csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boxoffice = read_tsv_qz(boxoffice_csv, zip=False)\n",
    "df_boxoffice = df_boxoffice.sort_values(by='lifetime_gross', ascending=False)\n",
    "df_boxoffice = df_boxoffice.drop_duplicates(subset='title', keep='first')\n",
    "df_boxoffice = df_boxoffice.dropna(subset=['studio'])\n",
    "df_boxoffice = df_boxoffice.drop('rank', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the title_basics and boxofffice datasets based on title and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df_title_basics.merge(df_boxoffice, left_on='primaryTitle', right_on='title')\n",
    "merged_df = merged_df.drop(columns=[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extensive filtering to ensure proper matching between movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['startYear'] = merged_df['startYear'].astype(int)\n",
    "merged_df = merged_df[(merged_df['startYear'] >= merged_df['year'] - 1) & (merged_df['startYear'] <= merged_df['year'] + 1)]\n",
    "tconst_list = merged_df['tconst'].tolist()\n",
    "merged_df = merged_df.drop(columns=[\"studio\", \"year\"])\n",
    "merged_df['lifetime_gross'] = merged_df['lifetime_gross'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export movies not in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df_title_basics[~df_title_basics['tconst'].isin(tconst_list)]\n",
    "filtered_df[['tconst']].to_csv('RawData/tconst_not_in_dataset_csv_filtered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_boxoffice\n",
    "del filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding OMDb API boxoffice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api = read_tsv_qz(data_api_csv, zip=False)\n",
    "df_api = df_api.dropna(subset=['BoxOffice'])\n",
    "df_api = df_api.drop_duplicates(subset=['tconst'], keep='first')\n",
    "df_api = df_api.rename(columns={'BoxOffice': 'lifetime_gross'})\n",
    "df_api['lifetime_gross'] = df_api['lifetime_gross'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Wikidata query data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikidata = read_tsv_qz(wikidata_csv, zip=False)\n",
    "df_wikidata = df_wikidata.drop(columns=['item', 'itemLabel'])\n",
    "df_wikidata = df_wikidata.rename(columns={'domesticGross': 'lifetime_gross', 'imdbID': 'tconst'})\n",
    "df_wikidata = df_wikidata.drop_duplicates(subset=['tconst'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate wikidata and api datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikidata_api = pd.concat([df_wikidata, df_api])\n",
    "df_wikidata_api = df_wikidata_api.drop_duplicates(subset=['tconst'], keep='first')\n",
    "df_wikidata_api = df_wikidata_api.rename(columns={'tconst': 'titleId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_wikidata\n",
    "del df_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = df_title_basics.merge(df_wikidata_api, left_on='tconst', right_on='titleId')\n",
    "aux = aux.drop(columns=[\"titleId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([merged_df, aux])\n",
    "merged_df = merged_df.drop_duplicates(subset=['tconst'], keep='first')\n",
    "tconst_list = merged_df['tconst'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del aux\n",
    "del df_title_basics\n",
    "del df_wikidata_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the akas tsv file and extracting new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_akas = read_tsv_qz(title_akas_tsv)\n",
    "df_akas = df_akas[df_akas['titleId'].isin(tconst_list)]\n",
    "df_akas = df_akas.sort_values(by='ordering', ascending=False)\n",
    "df_akas = df_akas.drop_duplicates(subset='titleId', keep='first')\n",
    "df_akas = df_akas.drop(columns=['title', 'region', 'language', 'types',\n",
    "       'attributes', 'isOriginalTitle'])\n",
    "df_akas = df_akas.rename(columns={'ordering': 'nrOfReleases'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(df_akas, left_on='tconst', right_on='titleId')\n",
    "merged_df = merged_df.drop(columns=[\"titleId\"])\n",
    "\n",
    "tconst_list = merged_df['tconst'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_akas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the crew tsv file and extracting new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crew = read_tsv_qz(title_crew_tsv)\n",
    "df_crew = df_crew[df_crew['tconst'].isin(tconst_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crew['directors'] = df_crew['directors'].str.split(',')  # Split the directors column by comma\n",
    "df_crew = df_crew.explode('directors')  # Explode the rows with multiple directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crew_full = read_tsv_qz(title_crew_tsv)\n",
    "df_crew_full['directors'] = df_crew_full['directors'].str.split(',')\n",
    "df_crew_full = df_crew_full.explode('directors')\n",
    "director_counts = df_crew_full['directors'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_crew_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crew['director_count'] = df_crew['directors'].map(director_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del director_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crew = df_crew.sort_values(by='director_count', ascending=False)\n",
    "df_crew = df_crew.drop_duplicates(subset='tconst', keep='first')\n",
    "df_crew = df_crew.drop(columns=['writers'])\n",
    "df_crew = df_crew.rename(columns={'tconst': 'titleId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(df_crew, left_on='tconst', right_on='titleId')\n",
    "merged_df = merged_df.drop(columns=[\"titleId\"])\n",
    "merged_df = merged_df[merged_df['directors'] != '\\\\N']\n",
    "merged_df = merged_df.drop(columns=['directors'])\n",
    "merged_df = merged_df[merged_df['genres'] != '\\\\N']\n",
    "merged_df = merged_df[merged_df['runtimeMinutes'] != '\\\\N']\n",
    "\n",
    "tconst_list = merged_df['tconst'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_crew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the principals tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_principal = read_tsv_qz(title_principals_tsv)\n",
    "df_principal = df_principal[df_principal['tconst'].isin(tconst_list)]\n",
    "df_principal['max_ordering'] = df_principal.groupby('tconst')['ordering'].transform('max')\n",
    "df_principal.loc[df_principal['category'].isin(['actor', 'actress']), 'category'] = 'a'\n",
    "df_principal['count_category_a'] = df_principal.groupby('tconst')['category'].transform(lambda x: x[x == 'a'].count())\n",
    "df_principal = df_principal.drop(columns=['ordering', 'nconst', 'job', 'characters', 'category'])\n",
    "df_principal = df_principal.drop_duplicates(subset='tconst', keep='first')\n",
    "df_principal = df_principal.rename(columns={'tconst': 'titleId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(df_principal, left_on='tconst', right_on='titleId')\n",
    "merged_df = merged_df.drop(columns=[\"titleId\"])\n",
    "merged_df = merged_df.drop(columns=['originalTitle'])\n",
    "merged_df = merged_df.rename(columns={'startYear': 'releaseYear', 'count_category_a': 'nrOfActors', 'lifetime_gross': 'lifetimeGross', 'director_count': 'director_nrOfMovies', 'max_ordering': 'nrOfEmployees'})\n",
    "\n",
    "tconst_list = merged_df['tconst'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = read_tsv_qz(title_ratings_tsv)\n",
    "df_ratings = df_ratings[df_ratings['tconst'].isin(tconst_list)]\n",
    "df_ratings = df_ratings.rename(columns={'tconst': 'titleId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(df_ratings, left_on='tconst', right_on='titleId')\n",
    "\n",
    "tconst_list = merged_df['tconst'].tolist()\n",
    "merged_df = merged_df.drop(columns=[\"titleId\", \"tconst\", \"primaryTitle\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/td/hh6f_yhd28q6g56x8wwsht340000gn/T/ipykernel_11611/1708109223.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(f, delimiter=sep)\n"
     ]
    }
   ],
   "source": [
    "aux_df = read_tsv_qz(title_basics_tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/td/hh6f_yhd28q6g56x8wwsht340000gn/T/ipykernel_11611/1708109223.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(f, delimiter=sep)\n"
     ]
    }
   ],
   "source": [
    "aux_df = read_tsv_qz(title_basics_tsv)\n",
    "aux_df = aux_df[aux_df['titleType'] == 'movie']\n",
    "aux_df = aux_df[['tconst', 'startYear']]\n",
    "aux_df = aux_df[aux_df['startYear'] != '\\\\N']\n",
    "aux_df['startYear'] = aux_df['startYear'].astype(int)\n",
    "release_year_counts = aux_df['startYear'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['releaseYear'] = merged_df['releaseYear'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "del aux_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['sameYearTotalMoviesReleased'] = merged_df['releaseYear'].map(release_year_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv_qz(merged_df, 'CleanedData/dataset.csv', zip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
